{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be44f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf lightning_logs\n",
    "import torch # Pytorch主套件\n",
    "from torch import nn # 神經網路層相關子套件\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data # Data讀取相關子套件 \n",
    "\n",
    "from torchvision.datasets import MNIST # MNIST資料集\n",
    "from torchvision import transforms as trans # 圖形前處理子套件\n",
    "\n",
    "import pytorch_lightning as pl # Lightning 主套件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17acd0ec",
   "metadata": {},
   "source": [
    "## Module class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0363b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---最簡單的Lightning Module---\n",
    "class LitModel(pl.LightningModule):\n",
    "    # ---初始化---\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # ---至少要放一個網路(把結構放在這邊，Sequential或者layers都可以)---\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    # ---網路走法(如果有skipping, concatenate, 還有tensor操作在這邊)---    \n",
    "    def forward(self,x):\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        return self.net(x)\n",
    "    \n",
    "    # ---每個training batch要做的事---    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # ---分開data, label---\n",
    "        x, y = batch\n",
    "        # ---data進網路---\n",
    "        y_hat = self(x)\n",
    "        # ---prediction跟y算loss---\n",
    "        loss = F.cross_entropy(y_hat, y) # cross_entropy裡面包含softmax計算\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # ---Optimizer放這邊---\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2539dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1024\n",
    "EPOCHS=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61570a81",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c08603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---讀取dataset---\n",
    "MNIST_train=MNIST(\".\", download=True,train=True, transform=trans.ToTensor())\n",
    "\n",
    "# ---將dataset放進dataloader(平行執行, 分batch_size, shuffle等功能)---\n",
    "train_loader = data.DataLoader(MNIST_train,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0782eea",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15ccc7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1295: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  \"GPU available but not used. Set the gpus flag in your trainer\"\n"
     ]
    }
   ],
   "source": [
    "# ---建立Trainer(負責model fitting, 紀錄訓練內容)---\n",
    "trainer = pl.Trainer(max_epochs=EPOCHS)\n",
    "# ---建立Model class---\n",
    "model = LitModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c7965",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1443a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | Sequential | 101 K \n",
      "------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb4855a666347278dfaaaac12f87754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''訓練開始'''\n",
    "trainer.fit(model,train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e892a49",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e85a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "\n",
    "class ModelWithLog(LitModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        ### --------------之前就有的-------------\n",
    "        # ---分開data, label---\n",
    "        x, y = batch\n",
    "        # ---data進網路---\n",
    "        y_hat = self(x)\n",
    "        # ---prediction跟y算loss---\n",
    "        loss = F.cross_entropy(y_hat, y) # cross_entropy裡面包含softmax計算\n",
    "        \n",
    "        \n",
    "        ### --------------紀錄用區段-------------\n",
    "        # ---算acc---\n",
    "        acc=accuracy(y_hat, y)\n",
    "        # ---記錄起來---\n",
    "        self.log(\"train_loss\",loss,prog_bar=True,logger=True)\n",
    "        self.log(\"train_acc\",acc,prog_bar=True,logger=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37df6395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | Sequential | 101 K \n",
      "------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137a6ab2d6e145e0bbf5174d7c114214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 58it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ModelWithLog()\n",
    "trainer.fit(model,train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147ffd17",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce194858",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithTest(ModelWithLog):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    ## ---跟trainin step基本一樣---\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ### --------------之前就有的-------------\n",
    "        # ---分開data, label---\n",
    "        x, y = batch\n",
    "        # ---data進網路---\n",
    "        y_hat = self(x)\n",
    "        # ---prediction跟y算loss---\n",
    "        loss = F.cross_entropy(y_hat, y) # cross_entropy裡面包含softmax計算\n",
    "        \n",
    "        acc=accuracy(y_hat, y)\n",
    "        # ---記錄起來---\n",
    "        self.log(\"test_loss\",loss,prog_bar=True,logger=True)\n",
    "        self.log(\"test_acc\",acc,prog_bar=True,logger=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a161baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | Sequential | 101 K \n",
      "------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224cd422b9cd427b9e518c33c06dc449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 58it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''先train'''\n",
    "model = ModelWithTest()\n",
    "trainer.fit(model,train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08249765",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "710f5e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---讀取dataset---\n",
    "MNIST_test=MNIST(\".\", download=True,train=False, transform=trans.ToTensor()) # testing dataset\n",
    "\n",
    "# ---將dataset放進dataloader(平行執行, 分batch_size, shuffle等功能)---\n",
    "test_loader = data.DataLoader(MNIST_test,batch_size=BATCH_SIZE*2,shuffle=True) # testing loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32c2f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:377: UserWarning: Your test_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  f\"Your {mode}_dataloader has `shuffle=True`, it is best practice to turn\"\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4b84a1fbad483bbbb8ab64c2d9e63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.9535999894142151, 'test_loss': 0.14951574802398682}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.14951574802398682, 'test_acc': 0.9535999894142151}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc6b76d",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a9985f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c74e8a",
   "metadata": {},
   "source": [
    "## 提高整合性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "35b7365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---最簡單的Lightning Module---\n",
    "class Model(pl.LightningModule):\n",
    "    # ---初始化---\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # ---至少要放一個網路(把結構放在這邊，Sequential或者layers都可以)---\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    # ---網路走法(如果有skipping, concatenate, 還有tensor操作在這邊)---    \n",
    "    def forward(self,x):\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        return self.net(x)\n",
    "    \n",
    "    # ---每個training batch要做的事---    \n",
    "    def training_step(self, batch, batch_idx,flag=\"train\"):\n",
    "        # ---分開data, label---\n",
    "        x, y = batch\n",
    "        \n",
    "        # ---data進網路---\n",
    "        y_hat = self(x)\n",
    "        \n",
    "        # ---prediction跟y算loss,acc---\n",
    "        loss = F.cross_entropy(y_hat, y) # cross_entropy裡面包含softmax計算\n",
    "        acc=accuracy(y_hat, y)\n",
    "        \n",
    "        # ---記錄起來---\n",
    "        self.log_dict({flag+\"_loss\":loss,flag+\"_acc\":acc},prog_bar=True,logger=True)\n",
    "        return loss\n",
    "    \n",
    "    # ---Optimizer放這邊---\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "    \n",
    "    # ---重複利用step function---\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.training_step(batch, batch_idx,flag=\"test\")\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.training_step(batch, batch_idx,flag=\"val\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0772698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | Sequential | 101 K \n",
      "------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4215242d47c84712ac1bc3b8f10f03b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 58it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "trainer.fit(model,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c4f394d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa53947d89524d7d9ba79de9d393722a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.953499972820282, 'test_loss': 0.1558782011270523}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.1558782011270523, 'test_acc': 0.953499972820282}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb7f7c",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97ba3b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## ---Evaluation mode---\n",
    "model.eval()\n",
    "\n",
    "for ii in range(10):\n",
    "    x=MNIST_test[ii][0]\n",
    "    y=MNIST_test[ii][1]\n",
    "    \n",
    "    # ---關掉gradient 計算---\n",
    "    with torch.no_grad():\n",
    "        # ---計算output---\n",
    "        pred = model(x)\n",
    "        plt.subplot(1,10,ii+1)\n",
    "        plt.imshow(x.squeeze(),\"gray\")\n",
    "        plt.title(pred.argmax(-1).item())\n",
    "        plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
